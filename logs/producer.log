2022-11-19 06:46:17,482 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:46:17,484 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:46:17,486 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:46:17,596 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:46:17,598 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:46:17,608 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:46:17,609 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:46:17,610 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 06:52:28,033 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:52:28,035 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:52:28,037 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:52:28,157 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:52:28,158 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:52:28,166 [__main__] [ERROR] 
Traceback (most recent call last):
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\src\producer.py", line 27, in <module>
    producer.send(topic='dev_test', value=event)
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\venv\lib\site-packages\kafka\producer\kafka.py", line 585, in send
    assert type(value_bytes) in (bytes, bytearray, memoryview, type(None))
AssertionError
2022-11-19 06:52:28,171 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:52:28,172 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 06:53:02,714 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:53:02,716 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:53:02,718 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:53:02,828 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:53:02,830 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:53:02,838 [__main__] [ERROR] Object of type datetime is not JSON serializable
Traceback (most recent call last):
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\src\producer.py", line 30, in <module>
    producer.send(topic='dev_test', value=event)
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\venv\lib\site-packages\kafka\producer\kafka.py", line 581, in send
    value_bytes = self._serialize(
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\venv\lib\site-packages\kafka\producer\kafka.py", line 714, in _serialize
    return f(data)
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\src\producer.py", line 12, in value_serializer
    return json.dumps(data).encode('utf-8')
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type datetime is not JSON serializable
2022-11-19 06:53:02,854 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:53:02,856 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 06:55:35,087 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:55:35,088 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:55:35,090 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:55:35,210 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:55:35,212 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:55:35,222 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:55:35,223 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 06:56:43,821 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:56:43,825 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:56:43,827 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:56:43,939 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:56:43,941 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:56:43,953 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:56:43,953 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:56:43,955 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 06:57:02,815 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:57:02,817 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:57:02,819 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:57:02,939 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:57:02,942 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:57:02,964 [__main__] [ERROR] Object of type bytes is not JSON serializable
Traceback (most recent call last):
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\src\producer.py", line 29, in <module>
    producer.send(topic='dev_test', value=b'test')
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\venv\lib\site-packages\kafka\producer\kafka.py", line 581, in send
    value_bytes = self._serialize(
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\venv\lib\site-packages\kafka\producer\kafka.py", line 714, in _serialize
    return f(data)
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\src\producer.py", line 11, in value_serializer
    return json.dumps(data).encode('utf-8')
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\ML\AppData\Local\Programs\Python\Python310\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type bytes is not JSON serializable
2022-11-19 06:57:02,973 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:57:02,975 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 06:57:14,263 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:57:14,265 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:57:14,268 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:57:14,387 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:57:14,390 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:57:14,397 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:57:14,398 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:57:14,399 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 06:57:14,400 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:59:09,917 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:59:09,919 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 06:59:09,921 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 06:59:10,037 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 06:59:10,039 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 06:59:10,049 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 06:59:10,049 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 06:59:10,051 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:00:49,734 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:00:49,736 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:00:49,738 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:00:49,851 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:00:49,853 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:00:49,862 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:00:49,862 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:00:49,864 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:01:16,780 [kafka.producer.kafka] [DEBUG] Starting the Kafka producer
2022-11-19 07:01:16,783 [kafka.metrics.metrics] [DEBUG] Added sensor with name connections-closed
2022-11-19 07:01:16,784 [kafka.metrics.metrics] [DEBUG] Added sensor with name connections-created
2022-11-19 07:01:16,786 [kafka.metrics.metrics] [DEBUG] Added sensor with name select-time
2022-11-19 07:01:16,788 [kafka.metrics.metrics] [DEBUG] Added sensor with name io-time
2022-11-19 07:01:16,789 [kafka.client] [DEBUG] Initiating connection to node bootstrap-0 at localhost:29092
2022-11-19 07:01:16,791 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes-sent-received
2022-11-19 07:01:16,793 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes-sent
2022-11-19 07:01:16,794 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes-received
2022-11-19 07:01:16,795 [kafka.metrics.metrics] [DEBUG] Added sensor with name request-latency
2022-11-19 07:01:16,797 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-bootstrap-0.bytes-sent
2022-11-19 07:01:16,798 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-bootstrap-0.bytes-received
2022-11-19 07:01:16,800 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-bootstrap-0.latency
2022-11-19 07:01:16,817 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <disconnected> [unspecified None]>: creating new socket
2022-11-19 07:01:16,820 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <disconnected> [IPv6 ('::1', 29092, 0, 0)]>: setting socket option (6, 1, 1)
2022-11-19 07:01:16,822 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:01:16,824 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:01:16,827 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: established TCP connection
2022-11-19 07:01:16,829 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:01:16,831 [kafka.client] [DEBUG] Node bootstrap-0 connected
2022-11-19 07:01:16,834 [kafka.protocol.parser] [DEBUG] Sending request ApiVersionRequest_v0()
2022-11-19 07:01:16,837 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 1: ApiVersionRequest_v0()
2022-11-19 07:01:16,950 [kafka.protocol.parser] [DEBUG] Sending request MetadataRequest_v0(topics=[])
2022-11-19 07:01:16,952 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 2: MetadataRequest_v0(topics=[])
2022-11-19 07:01:16,955 [kafka.protocol.parser] [DEBUG] Received correlation id: 1
2022-11-19 07:01:16,957 [kafka.protocol.parser] [DEBUG] Processing response ApiVersionResponse_v0
2022-11-19 07:01:16,959 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 1 (119.1864013671875 ms): ApiVersionResponse_v0(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=9), (api_key=1, min_version=0, max_version=13), (api_key=2, min_version=0, max_version=7), (api_key=3, min_version=0, max_version=12), (api_key=4, min_version=0, max_version=6), (api_key=5, min_version=0, max_version=3), (api_key=6, min_version=0, max_version=7), (api_key=7, min_version=0, max_version=3), (api_key=8, min_version=0, max_version=8), (api_key=9, min_version=0, max_version=8), (api_key=10, min_version=0, max_version=4), (api_key=11, min_version=0, max_version=9), (api_key=12, min_version=0, max_version=4), (api_key=13, min_version=0, max_version=5), (api_key=14, min_version=0, max_version=5), (api_key=15, min_version=0, max_version=5), (api_key=16, min_version=0, max_version=4), (api_key=17, min_version=0, max_version=1), (api_key=18, min_version=0, max_version=3), (api_key=19, min_version=0, max_version=7), (api_key=20, min_version=0, max_version=6), (api_key=21, min_version=0, max_version=2), (api_key=22, min_version=0, max_version=4), (api_key=23, min_version=0, max_version=4), (api_key=24, min_version=0, max_version=3), (api_key=25, min_version=0, max_version=3), (api_key=26, min_version=0, max_version=3), (api_key=27, min_version=0, max_version=1), (api_key=28, min_version=0, max_version=3), (api_key=29, min_version=0, max_version=2), (api_key=30, min_version=0, max_version=2), (api_key=31, min_version=0, max_version=2), (api_key=32, min_version=0, max_version=4), (api_key=33, min_version=0, max_version=2), (api_key=34, min_version=0, max_version=2), (api_key=35, min_version=0, max_version=3), (api_key=36, min_version=0, max_version=2), (api_key=37, min_version=0, max_version=3), (api_key=38, min_version=0, max_version=2), (api_key=39, min_version=0, max_version=2), (api_key=40, min_version=0, max_version=2), (api_key=41, min_version=0, max_version=2), (api_key=42, min_version=0, max_version=2), (api_key=43, min_version=0, max_version=2), (api_key=44, min_version=0, max_version=1), (api_key=45, min_version=0, max_version=0), (api_key=46, min_version=0, max_version=0), (api_key=47, min_version=0, max_version=0), (api_key=48, min_version=0, max_version=1), (api_key=49, min_version=0, max_version=1), (api_key=50, min_version=0, max_version=0), (api_key=51, min_version=0, max_version=0), (api_key=56, min_version=0, max_version=1), (api_key=57, min_version=0, max_version=0), (api_key=60, min_version=0, max_version=0), (api_key=61, min_version=0, max_version=0), (api_key=65, min_version=0, max_version=0), (api_key=66, min_version=0, max_version=0), (api_key=67, min_version=0, max_version=0)])
2022-11-19 07:01:16,973 [kafka.protocol.parser] [DEBUG] Received correlation id: 2
2022-11-19 07:01:16,975 [kafka.protocol.parser] [DEBUG] Processing response MetadataResponse_v0
2022-11-19 07:01:16,977 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 2 (21.489381790161133 ms): MetadataResponse_v0(brokers=[(node_id=1, host='localhost', port=29092)], topics=[(error_code=0, topic='__transaction_state', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='default_ksql_processing_log', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='_confluent-ksql-default__command_topic', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='dev_test', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='__consumer_offsets', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])])])
2022-11-19 07:01:17,031 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:01:17,036 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:01:17,040 [kafka.metrics.metrics] [DEBUG] Added sensor with name bufferpool-wait-time
2022-11-19 07:01:17,042 [kafka.metrics.metrics] [DEBUG] Added sensor with name batch-size
2022-11-19 07:01:17,044 [kafka.metrics.metrics] [DEBUG] Added sensor with name compression-rate
2022-11-19 07:01:17,045 [kafka.metrics.metrics] [DEBUG] Added sensor with name queue-time
2022-11-19 07:01:17,047 [kafka.metrics.metrics] [DEBUG] Added sensor with name produce-throttle-time
2022-11-19 07:01:17,050 [kafka.metrics.metrics] [DEBUG] Added sensor with name records-per-request
2022-11-19 07:01:17,052 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes
2022-11-19 07:01:17,054 [kafka.metrics.metrics] [DEBUG] Added sensor with name record-retries
2022-11-19 07:01:17,056 [kafka.metrics.metrics] [DEBUG] Added sensor with name errors
2022-11-19 07:01:17,058 [kafka.metrics.metrics] [DEBUG] Added sensor with name record-size-max
2022-11-19 07:01:17,061 [kafka.producer.sender] [DEBUG] Starting Kafka producer I/O thread.
2022-11-19 07:01:17,061 [kafka.producer.kafka] [DEBUG] Kafka producer started
2022-11-19 07:01:17,062 [kafka.client] [DEBUG] Sending metadata request MetadataRequest_v1(topics=NULL) to node bootstrap-0
2022-11-19 07:01:17,064 [kafka.producer.kafka] [DEBUG] Requesting metadata update for topic dev_test
2022-11-19 07:01:17,064 [kafka.protocol.parser] [DEBUG] Sending request MetadataRequest_v1(topics=NULL)
2022-11-19 07:01:17,066 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 3: MetadataRequest_v1(topics=NULL)
2022-11-19 07:01:17,072 [kafka.protocol.parser] [DEBUG] Received correlation id: 3
2022-11-19 07:01:17,073 [kafka.protocol.parser] [DEBUG] Processing response MetadataResponse_v1
2022-11-19 07:01:17,077 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 3 (8.583545684814453 ms): MetadataResponse_v1(brokers=[(node_id=1, host='localhost', port=29092, rack=None)], controller_id=1, topics=[(error_code=0, topic='__transaction_state', is_internal=True, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='default_ksql_processing_log', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='_confluent-ksql-default__command_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='dev_test', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='__consumer_offsets', is_internal=True, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])])])
2022-11-19 07:01:17,104 [kafka.cluster] [DEBUG] Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 5, groups: 0)
2022-11-19 07:01:17,104 [kafka.producer.kafka] [DEBUG] _wait_on_metadata woke after 0.040627479553222656 secs.
2022-11-19 07:01:17,108 [kafka.producer.kafka] [DEBUG] Sending (key=None value=b'test' headers=[]) to TopicPartition(topic='dev_test', partition=0)
2022-11-19 07:01:17,109 [kafka.producer.record_accumulator] [DEBUG] Allocating a new 16384 byte message buffer for TopicPartition(topic='dev_test', partition=0)
2022-11-19 07:01:17,111 [kafka.producer.kafka] [DEBUG] Waking up the sender since TopicPartition(topic='dev_test', partition=0) is either full or getting a new batch
2022-11-19 07:01:17,113 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:01:17,113 [kafka.producer.sender] [DEBUG] Node 1 not ready; delaying produce of accumulated batch
2022-11-19 07:01:17,114 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:01:17,115 [kafka.client] [DEBUG] Initiating connection to node 1 at localhost:29092
2022-11-19 07:01:17,116 [kafka.producer.kafka] [DEBUG] The Kafka producer has closed.
2022-11-19 07:01:17,118 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-1.bytes-sent
2022-11-19 07:01:41,900 [kafka.producer.kafka] [DEBUG] Starting the Kafka producer
2022-11-19 07:01:41,903 [kafka.metrics.metrics] [DEBUG] Added sensor with name connections-closed
2022-11-19 07:01:41,904 [kafka.metrics.metrics] [DEBUG] Added sensor with name connections-created
2022-11-19 07:01:41,905 [kafka.metrics.metrics] [DEBUG] Added sensor with name select-time
2022-11-19 07:01:41,906 [kafka.metrics.metrics] [DEBUG] Added sensor with name io-time
2022-11-19 07:01:41,907 [kafka.client] [DEBUG] Initiating connection to node bootstrap-0 at localhost:29092
2022-11-19 07:01:41,909 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes-sent-received
2022-11-19 07:01:41,910 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes-sent
2022-11-19 07:01:41,911 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes-received
2022-11-19 07:01:41,912 [kafka.metrics.metrics] [DEBUG] Added sensor with name request-latency
2022-11-19 07:01:41,913 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-bootstrap-0.bytes-sent
2022-11-19 07:01:41,914 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-bootstrap-0.bytes-received
2022-11-19 07:01:41,914 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-bootstrap-0.latency
2022-11-19 07:01:41,926 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <disconnected> [unspecified None]>: creating new socket
2022-11-19 07:01:41,927 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <disconnected> [IPv6 ('::1', 29092, 0, 0)]>: setting socket option (6, 1, 1)
2022-11-19 07:01:41,927 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:01:41,928 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:01:41,929 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: established TCP connection
2022-11-19 07:01:41,930 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:01:41,930 [kafka.client] [DEBUG] Node bootstrap-0 connected
2022-11-19 07:01:41,931 [kafka.protocol.parser] [DEBUG] Sending request ApiVersionRequest_v0()
2022-11-19 07:01:41,932 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 1: ApiVersionRequest_v0()
2022-11-19 07:01:42,046 [kafka.protocol.parser] [DEBUG] Sending request MetadataRequest_v0(topics=[])
2022-11-19 07:01:42,047 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 2: MetadataRequest_v0(topics=[])
2022-11-19 07:01:42,050 [kafka.protocol.parser] [DEBUG] Received correlation id: 1
2022-11-19 07:01:42,051 [kafka.protocol.parser] [DEBUG] Processing response ApiVersionResponse_v0
2022-11-19 07:01:42,053 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 1 (121.81282043457031 ms): ApiVersionResponse_v0(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=9), (api_key=1, min_version=0, max_version=13), (api_key=2, min_version=0, max_version=7), (api_key=3, min_version=0, max_version=12), (api_key=4, min_version=0, max_version=6), (api_key=5, min_version=0, max_version=3), (api_key=6, min_version=0, max_version=7), (api_key=7, min_version=0, max_version=3), (api_key=8, min_version=0, max_version=8), (api_key=9, min_version=0, max_version=8), (api_key=10, min_version=0, max_version=4), (api_key=11, min_version=0, max_version=9), (api_key=12, min_version=0, max_version=4), (api_key=13, min_version=0, max_version=5), (api_key=14, min_version=0, max_version=5), (api_key=15, min_version=0, max_version=5), (api_key=16, min_version=0, max_version=4), (api_key=17, min_version=0, max_version=1), (api_key=18, min_version=0, max_version=3), (api_key=19, min_version=0, max_version=7), (api_key=20, min_version=0, max_version=6), (api_key=21, min_version=0, max_version=2), (api_key=22, min_version=0, max_version=4), (api_key=23, min_version=0, max_version=4), (api_key=24, min_version=0, max_version=3), (api_key=25, min_version=0, max_version=3), (api_key=26, min_version=0, max_version=3), (api_key=27, min_version=0, max_version=1), (api_key=28, min_version=0, max_version=3), (api_key=29, min_version=0, max_version=2), (api_key=30, min_version=0, max_version=2), (api_key=31, min_version=0, max_version=2), (api_key=32, min_version=0, max_version=4), (api_key=33, min_version=0, max_version=2), (api_key=34, min_version=0, max_version=2), (api_key=35, min_version=0, max_version=3), (api_key=36, min_version=0, max_version=2), (api_key=37, min_version=0, max_version=3), (api_key=38, min_version=0, max_version=2), (api_key=39, min_version=0, max_version=2), (api_key=40, min_version=0, max_version=2), (api_key=41, min_version=0, max_version=2), (api_key=42, min_version=0, max_version=2), (api_key=43, min_version=0, max_version=2), (api_key=44, min_version=0, max_version=1), (api_key=45, min_version=0, max_version=0), (api_key=46, min_version=0, max_version=0), (api_key=47, min_version=0, max_version=0), (api_key=48, min_version=0, max_version=1), (api_key=49, min_version=0, max_version=1), (api_key=50, min_version=0, max_version=0), (api_key=51, min_version=0, max_version=0), (api_key=56, min_version=0, max_version=1), (api_key=57, min_version=0, max_version=0), (api_key=60, min_version=0, max_version=0), (api_key=61, min_version=0, max_version=0), (api_key=65, min_version=0, max_version=0), (api_key=66, min_version=0, max_version=0), (api_key=67, min_version=0, max_version=0)])
2022-11-19 07:01:42,063 [kafka.protocol.parser] [DEBUG] Received correlation id: 2
2022-11-19 07:01:42,064 [kafka.protocol.parser] [DEBUG] Processing response MetadataResponse_v0
2022-11-19 07:01:42,066 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 2 (16.552209854125977 ms): MetadataResponse_v0(brokers=[(node_id=1, host='localhost', port=29092)], topics=[(error_code=0, topic='__transaction_state', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='default_ksql_processing_log', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='_confluent-ksql-default__command_topic', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='dev_test', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='__consumer_offsets', partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])])])
2022-11-19 07:01:42,086 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:01:42,088 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:01:42,091 [kafka.metrics.metrics] [DEBUG] Added sensor with name bufferpool-wait-time
2022-11-19 07:01:42,093 [kafka.metrics.metrics] [DEBUG] Added sensor with name batch-size
2022-11-19 07:01:42,095 [kafka.metrics.metrics] [DEBUG] Added sensor with name compression-rate
2022-11-19 07:01:42,096 [kafka.metrics.metrics] [DEBUG] Added sensor with name queue-time
2022-11-19 07:01:42,097 [kafka.metrics.metrics] [DEBUG] Added sensor with name produce-throttle-time
2022-11-19 07:01:42,098 [kafka.metrics.metrics] [DEBUG] Added sensor with name records-per-request
2022-11-19 07:01:42,099 [kafka.metrics.metrics] [DEBUG] Added sensor with name bytes
2022-11-19 07:01:42,101 [kafka.metrics.metrics] [DEBUG] Added sensor with name record-retries
2022-11-19 07:01:42,103 [kafka.metrics.metrics] [DEBUG] Added sensor with name errors
2022-11-19 07:01:42,104 [kafka.metrics.metrics] [DEBUG] Added sensor with name record-size-max
2022-11-19 07:01:42,107 [kafka.producer.sender] [DEBUG] Starting Kafka producer I/O thread.
2022-11-19 07:01:42,108 [kafka.producer.kafka] [DEBUG] Kafka producer started
2022-11-19 07:01:42,110 [kafka.client] [DEBUG] Sending metadata request MetadataRequest_v1(topics=NULL) to node bootstrap-0
2022-11-19 07:01:42,112 [kafka.producer.kafka] [DEBUG] Requesting metadata update for topic dev_test
2022-11-19 07:01:42,113 [kafka.protocol.parser] [DEBUG] Sending request MetadataRequest_v1(topics=NULL)
2022-11-19 07:01:42,115 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Request 3: MetadataRequest_v1(topics=NULL)
2022-11-19 07:01:42,122 [kafka.protocol.parser] [DEBUG] Received correlation id: 3
2022-11-19 07:01:42,124 [kafka.protocol.parser] [DEBUG] Processing response MetadataResponse_v1
2022-11-19 07:01:42,127 [kafka.conn] [DEBUG] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]> Response 3 (9.002685546875 ms): MetadataResponse_v1(brokers=[(node_id=1, host='localhost', port=29092, rack=None)], controller_id=1, topics=[(error_code=0, topic='__transaction_state', is_internal=True, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='default_ksql_processing_log', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='_confluent-ksql-default__command_topic', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='dev_test', is_internal=False, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1])]), (error_code=0, topic='__consumer_offsets', is_internal=True, partitions=[(error_code=0, partition=0, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=10, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=20, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=40, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=30, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=9, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=11, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=31, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=39, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=13, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=18, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=22, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=8, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=32, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=43, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=29, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=34, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=1, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=6, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=41, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=27, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=48, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=5, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=15, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=35, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=25, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=46, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=26, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=36, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=44, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=16, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=37, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=17, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=45, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=3, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=24, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=38, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=33, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=23, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=28, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=2, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=12, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=19, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=14, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=4, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=47, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=49, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=42, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=7, leader=1, replicas=[1], isr=[1]), (error_code=0, partition=21, leader=1, replicas=[1], isr=[1])])])
2022-11-19 07:01:42,146 [kafka.cluster] [DEBUG] Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 5, groups: 0)
2022-11-19 07:01:42,147 [kafka.producer.kafka] [DEBUG] _wait_on_metadata woke after 0.035688161849975586 secs.
2022-11-19 07:01:42,151 [kafka.producer.kafka] [DEBUG] Sending (key=None value=b'test' headers=[]) to TopicPartition(topic='dev_test', partition=0)
2022-11-19 07:01:42,153 [kafka.producer.record_accumulator] [DEBUG] Allocating a new 16384 byte message buffer for TopicPartition(topic='dev_test', partition=0)
2022-11-19 07:01:42,155 [kafka.producer.kafka] [DEBUG] Waking up the sender since TopicPartition(topic='dev_test', partition=0) is either full or getting a new batch
2022-11-19 07:01:42,157 [kafka.producer.sender] [DEBUG] Node 1 not ready; delaying produce of accumulated batch
2022-11-19 07:01:42,158 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:01:42,159 [kafka.client] [DEBUG] Initiating connection to node 1 at localhost:29092
2022-11-19 07:01:42,160 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:01:42,161 [kafka.metrics.metrics] [DEBUG] Added sensor with name node-1.bytes-sent
2022-11-19 07:01:42,162 [kafka.producer.kafka] [DEBUG] The Kafka producer has closed.
2022-11-19 07:05:45,457 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:05:45,459 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:05:45,460 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:05:45,579 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:05:45,580 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:05:45,587 [__main__] [ERROR] 
Traceback (most recent call last):
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\src\producer.py", line 28, in <module>
    producer.send('dev_test', 'test')
  File "C:\Users\ML\Documents\DEV\Kafka\ksql-demo\venv\lib\site-packages\kafka\producer\kafka.py", line 585, in send
    assert type(value_bytes) in (bytes, bytearray, memoryview, type(None))
AssertionError
2022-11-19 07:05:45,592 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:05:45,593 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:06:36,847 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:06:36,849 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:06:36,851 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:06:36,968 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:06:36,969 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:06:36,978 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:06:36,981 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:06:36,982 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:06:36,983 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:07:02,255 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2022-11-19 07:07:02,256 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:07:02,258 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2022-11-19 07:07:02,373 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:07:02,375 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:07:02,385 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:07:02,386 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:07:44,340 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:07:44,343 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:07:44,346 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:07:46,621 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:07:46,624 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:07:54,192 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2022-11-19 07:07:54,194 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:07:54,197 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2022-11-19 07:07:54,322 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:07:54,323 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:07:54,331 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:07:54,332 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:08:36,360 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2022-11-19 07:08:36,362 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:08:36,365 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2022-11-19 07:08:36,475 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:08:36,477 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:08:36,485 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:08:36,487 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:09:25,398 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2022-11-19 07:09:25,400 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:09:25,402 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
2022-11-19 07:09:25,523 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:09:25,524 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:09:27,816 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:27,818 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:30,111 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:30,114 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:32,405 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:32,408 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:34,703 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:34,704 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:36,981 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:36,984 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:39,270 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:39,273 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:41,578 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:41,581 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:43,865 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:43,867 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:46,139 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:46,140 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:48,433 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:48,435 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:50,705 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:50,706 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:52,985 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:52,988 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:55,280 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:55,283 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:57,561 [kafka.conn] [WARNING] DNS lookup failed for kafka:9092, exception was [Errno 11001] getaddrinfo failed. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?
2022-11-19 07:09:57,564 [kafka.conn] [ERROR] DNS lookup failed for kafka:9092 (AddressFamily.AF_UNSPEC)
2022-11-19 07:09:57,566 [kafka.producer.record_accumulator] [WARNING] Produced messages to topic-partition TopicPartition(topic='dev_test', partition=0) with base offset -1 log start offset None and error None.
2022-11-19 07:09:57,569 [kafka.producer.record_accumulator] [WARNING] Expired 1 batches in accumulator
2022-11-19 07:09:57,581 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:09:57,583 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:10:12,620 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:10:12,623 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:10:12,625 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:10:12,746 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:10:12,747 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:10:12,757 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:10:12,758 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:10:12,759 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. 
2022-11-19 07:10:12,768 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:10:12,770 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:13:59,528 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:13:59,529 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:13:59,531 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:13:59,653 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:13:59,655 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:13:59,663 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:13:59,665 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:13:59,666 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:14:30,355 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:14:30,357 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:14:30,358 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:14:30,482 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:14:30,483 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:14:30,493 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:14:30,495 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:14:30,496 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. 
2022-11-19 07:14:30,503 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:14:30,506 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:15:08,288 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:15:08,290 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:15:08,292 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:15:08,411 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:15:08,412 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:15:08,422 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:15:08,424 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:15:08,425 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. 
2022-11-19 07:15:08,432 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:15:08,435 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:15:17,270 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:15:17,272 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:15:17,274 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:15:17,387 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:15:17,388 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:15:17,398 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:15:17,400 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:15:17,401 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. 
2022-11-19 07:15:17,410 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:15:17,411 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:18:22,955 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:18:22,957 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:18:22,959 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:18:23,071 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:18:23,072 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:18:23,084 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:18:23,086 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:18:23,087 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. 
2022-11-19 07:18:58,310 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:18:58,312 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:23:19,440 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:23:19,442 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:23:19,444 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:23:19,551 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:23:19,552 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:23:19,559 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:23:19,561 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:23:19,562 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. 
2022-11-19 07:23:40,753 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:23:40,754 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2022-11-19 07:24:14,757 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:24:14,759 [kafka.conn] [INFO] Probing node bootstrap-0 broker version
2022-11-19 07:24:14,760 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:24:14,881 [kafka.conn] [INFO] Broker version identified as 2.5.0
2022-11-19 07:24:14,883 [kafka.conn] [INFO] Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
2022-11-19 07:24:14,893 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: connecting to localhost:29092 [('::1', 29092, 0, 0) IPv6]
2022-11-19 07:24:14,895 [kafka.conn] [INFO] <BrokerConnection node_id=1 host=localhost:29092 <connecting> [IPv6 ('::1', 29092, 0, 0)]>: Connection complete.
2022-11-19 07:24:14,896 [kafka.conn] [INFO] <BrokerConnection node_id=bootstrap-0 host=localhost:29092 <connected> [IPv6 ('::1', 29092, 0, 0)]>: Closing connection. 
2022-11-19 07:24:20,468 [kafka.producer.kafka] [INFO] Closing the Kafka producer with 0 secs timeout.
2022-11-19 07:24:20,469 [kafka.producer.kafka] [INFO] Proceeding to force close the producer since pending requests could not be completed within timeout 0.
